{
    "default": {
      "stage": "sft",
      "model_name_or_path": "codellama/CodeLlama-7b-hf",
      "dataset": "spider-sql-custom",
      "dataset_dir": "/home/users/h/huju/dev/BA/data",
      "do_train": true,
      "template": "default",
      "finetuning_type": "lora",
      "lora_target": "all",
      "per_device_train_batch_size": 4,
      "gradient_accumulation_steps": 4,
      "lr_scheduler_type": "cosine",
      "logging_steps": 10,
      "save_steps": 100,
      "learning_rate": 5e-05,
      "num_train_epochs": 5.0,
      "max_samples": 500,
      "max_grad_norm": 1.0,
      "fp16": true,
      "report_to": "wandb"
    },
    "longer-input": {
      "stage": "sft",
      "model_name_or_path": "codellama/CodeLlama-7b-hf",
      "dataset": "spider-sql-custom",
      "dataset_dir": "/home/users/h/huju/dev/BA/data",
      "do_train": true,
      "template": "default",
      "finetuning_type": "lora",
      "lora_target": "all",
      "per_device_train_batch_size": 4,
      "gradient_accumulation_steps": 4,
      "lr_scheduler_type": "cosine",
      "cutoff_len": 4096,
      "logging_steps": 10,
      "save_steps": 100,
      "learning_rate": 5e-05,
      "num_train_epochs": 5.0,
      "max_samples": 500,
      "max_grad_norm": 1.0,
      "fp16": true,
      "report_to": "wandb"
    },
    "all_samples": {
      "stage": "sft",
      "model_name_or_path": "codellama/CodeLlama-7b-hf",
      "dataset": "spider-sql-custom",
      "dataset_dir": "/home/users/h/huju/dev/BA/data",
      "do_train": true,
      "template": "default",
      "finetuning_type": "lora",
      "lora_target": "all",
      "per_device_train_batch_size": 4,
      "gradient_accumulation_steps": 4,
      "lr_scheduler_type": "cosine",
      "cutoff_len": 4096,
      "logging_steps": 10,
      "save_steps": 100,
      "learning_rate": 5e-05,
      "num_train_epochs": 5.0,
      "max_grad_norm": 1.0,
      "val_size": 0.2,
      "fp16": true,
      "report_to": "wandb"
    }
  }  